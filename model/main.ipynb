{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d207d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset , DataLoader, random_split\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imgDataset import imgDataset\n",
    "from EAST import EAST\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0a830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "directory_train = os.getenv('Directory_train')\n",
    "directory_train_textAndCoords = os.getenv('directory_train_textAndCoords')\n",
    "directory_test = os.getenv('Directory_test')\n",
    "directory_test_textAndCoords = os.getenv('directory_test_textAndCoords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c18ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path_imgs and path_labels\n",
    "path_imgs = os.listdir(directory_train)\n",
    "path_labels = os.listdir(directory_train_textAndCoords)\n",
    "\n",
    "# Generate paths for training images and labels\n",
    "train_img_paths = [os.path.join(directory_train, f) for f in path_imgs]\n",
    "train_label_paths = [os.path.join(directory_train_textAndCoords, f) for f in path_labels]\n",
    "\n",
    "#print(train_img_paths)\n",
    "#print(train_label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9be443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['377', '117', '463', '117', '465', '130', '378', '130']\n",
      "['493', '115', '519', '115', '519', '131', '493', '131']\n",
      "['374', '155', '409', '155', '409', '170', '374', '170']\n",
      "['492', '151', '551', '151', '551', '170', '492', '170']\n",
      "['376', '198', '422', '198', '422', '212', '376', '212']\n",
      "['494', '190', '539', '189', '539', '205', '494', '206']\n",
      "['374', '1', '494', '0', '492', '85', '372', '86']\n",
      "Image shape: torch.Size([1, 640, 360])\n",
      "First Label: [['G', 'e', 'n', 'a', 'x', 'i', 's', ' ', 'T', 'h', 'e', 'a', 't', 'r', 'e'], ['[', '0', '6', ']'], ['#', '#', '#'], ['6', '2', '-', '0', '3'], ['C', 'a', 'r', 'p', 'a', 'r', 'k'], ['#', '#', '#'], ['#', '#', '#']]\n",
      "First Coords: tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = [train_img_paths, train_label_paths]\n",
    "train_dataset = imgDataset(train_img_paths, train_label_paths)\n",
    "img, labels, coords = train_dataset[0]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\") # Should be [1, 360, 360] since it's grayscale\n",
    "print(f\"First Label: {labels}\")\n",
    "print(f\"First Coords: {coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bddb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spltining the dataset into training and validation sets\n",
    "val_split = 0.2\n",
    "training_size = int((1 - val_split) * len(train_dataset))\n",
    "val_size = len(train_dataset) - training_size\n",
    "training_dataset, val_dataset = random_split(train_dataset, [training_size, val_size])\n",
    "loader_train = DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
    "loader_val = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "#print(f\"loader_train: {loader_train}\")\n",
    "#print(f\"loader_val: {loader_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EAST(color_channel=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loasding model if it exists\n",
    "if os.getenv('Load_model') == 'True': \n",
    "    model.load_state_dict(torch.load(os.getenv('model_path')))\n",
    "    print(\"Model loaded successfully\")\n",
    "else:\n",
    "    print(\"Model not load, starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defualt model otipions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "cycles = 12\n",
    "train_model(model = model, loader_train = loader_train, loader_val = loader_val, criterion = criterion, optimizer = optimizer, cycles = cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.getenv('Model_save_path', 'east_model.pth')\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-east",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
