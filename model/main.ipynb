{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset , DataLoader, random_split\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imgDataset import imgDataset , custom_collate\n",
    "from EAST import EAST\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "directory_train = os.getenv('Directory_train')\n",
    "directory_train_textAndCoords = os.getenv('directory_train_textAndCoords')\n",
    "directory_test = os.getenv('Directory_test')\n",
    "directory_test_textAndCoords = os.getenv('directory_test_textAndCoords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path_imgs and path_labels\n",
    "path_imgs = os.listdir(directory_train)\n",
    "path_labels = os.listdir(directory_train_textAndCoords)\n",
    "\n",
    "# Generate paths for training images and labels\n",
    "train_img_paths = [os.path.join(directory_train, f) for f in path_imgs]\n",
    "train_label_paths = [os.path.join(directory_train_textAndCoords, f) for f in path_labels]\n",
    "\n",
    "#print(train_img_paths)\n",
    "#print(train_label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [train_img_paths, train_label_paths]\n",
    "train_dataset = imgDataset(train_img_paths, train_label_paths)\n",
    "img, labels, coords = train_dataset[3]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\") # Should be [1, 360, 360] since it's grayscale\n",
    "print(f\"First Coords: {coords}\")\n",
    "print(f\"First Coords:{len(coords)}\")\n",
    "\n",
    "'''max_len = max(len(train_dataset[j][2]) for j in range(len(train_dataset)))\n",
    "pad_len = max_len - len(train_dataset[3][2])\n",
    "print(pad_len)'''\n",
    "\n",
    "batch = custom_collate(train_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bddb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spltining the dataset into training and validation sets\n",
    "val_split = 0.2\n",
    "training_size = int((1 - val_split) * len(train_dataset))\n",
    "val_size = len(train_dataset) - training_size\n",
    "training_dataset, val_dataset = random_split(train_dataset, [training_size, val_size])\n",
    "loader_train = DataLoader(training_dataset, batch_size=32, shuffle=True, collate_fn = custom_collate)\n",
    "loader_val = DataLoader(val_dataset, batch_size=32, shuffle=True, collate_fn = custom_collate)\n",
    "\n",
    "#print(f\"loader_train: {loader_train}\")\n",
    "#print(f\"loader_val: {loader_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EAST(color_channel=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loasding model if it exists\n",
    "if os.getenv('Load_model') == 'True': \n",
    "    model.load_state_dict(torch.load(os.getenv('model_path')))\n",
    "    print(\"Model loaded successfully\")\n",
    "else:\n",
    "    print(\"Model not load, starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defualt model otipions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "cycles = 12\n",
    "train_model(model = model, loader_train = loader_train, loader_val = loader_val, criterion = criterion, optimizer = optimizer, cycles = cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.getenv('Model_save_path', 'east_model.pth')\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-east",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
