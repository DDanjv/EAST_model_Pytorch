{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d207d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s shape:  torch.Size([1, 16, 180, 320])\n",
      "f1 shape:  torch.Size([1, 64, 90, 160])\n",
      "f2 shape:  torch.Size([1, 128, 45, 80])\n",
      "f3 shape:  torch.Size([1, 256, 22, 40])\n",
      "f4 shape:  torch.Size([1, 512, 11, 20])\n",
      "h1 shape unpooled:  torch.Size([1, 512, 22, 40])\n",
      "f3 shape:  torch.Size([1, 256, 22, 40])\n",
      "torch.Size([1, 768, 22, 40])\n",
      "h2 :  torch.Size([1, 128, 22, 40])\n",
      "h2 shape unpooled:  torch.Size([1, 128, 45, 80])\n",
      "f2 shape:  torch.Size([1, 128, 45, 80])\n",
      "torch.Size([1, 256, 45, 80])\n",
      "h3 shape unpooled:  torch.Size([1, 32, 90, 160])\n",
      "f1 shape:  torch.Size([1, 64, 90, 160])\n",
      "score shape:  torch.Size([1, 1, 360, 640])\n",
      "tensor([[[[0.4578, 0.4583, 0.4588,  ..., 0.4618, 0.4619, 0.4620],\n",
      "          [0.4575, 0.4580, 0.4585,  ..., 0.4620, 0.4621, 0.4622],\n",
      "          [0.4572, 0.4577, 0.4582,  ..., 0.4622, 0.4623, 0.4624],\n",
      "          ...,\n",
      "          [0.4596, 0.4601, 0.4607,  ..., 0.4632, 0.4630, 0.4628],\n",
      "          [0.4603, 0.4606, 0.4610,  ..., 0.4627, 0.4627, 0.4627],\n",
      "          [0.4609, 0.4611, 0.4613,  ..., 0.4623, 0.4624, 0.4626]]]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "geo map : torch.Size([1, 8, 360, 640])\n",
      "tensor([[[[-0.7063, -0.7065, -0.7066,  ..., -0.7078, -0.7078, -0.7079],\n",
      "          [-0.7062, -0.7064, -0.7065,  ..., -0.7078, -0.7079, -0.7079],\n",
      "          [-0.7061, -0.7063, -0.7064,  ..., -0.7079, -0.7080, -0.7080],\n",
      "          ...,\n",
      "          [-0.7070, -0.7072, -0.7074,  ..., -0.7083, -0.7082, -0.7081],\n",
      "          [-0.7072, -0.7073, -0.7075,  ..., -0.7081, -0.7081, -0.7081],\n",
      "          [-0.7074, -0.7075, -0.7076,  ..., -0.7080, -0.7080, -0.7081]],\n",
      "\n",
      "         [[ 0.5548,  0.5545,  0.5542,  ...,  0.5524,  0.5523,  0.5522],\n",
      "          [ 0.5550,  0.5547,  0.5544,  ...,  0.5523,  0.5522,  0.5521],\n",
      "          [ 0.5552,  0.5549,  0.5546,  ...,  0.5522,  0.5521,  0.5520],\n",
      "          ...,\n",
      "          [ 0.5537,  0.5534,  0.5531,  ...,  0.5515,  0.5517,  0.5518],\n",
      "          [ 0.5533,  0.5531,  0.5529,  ...,  0.5518,  0.5518,  0.5518],\n",
      "          [ 0.5529,  0.5528,  0.5527,  ...,  0.5521,  0.5520,  0.5519]],\n",
      "\n",
      "         [[ 0.6141,  0.6144,  0.6147,  ...,  0.6165,  0.6166,  0.6166],\n",
      "          [ 0.6139,  0.6142,  0.6145,  ...,  0.6166,  0.6167,  0.6168],\n",
      "          [ 0.6138,  0.6141,  0.6144,  ...,  0.6167,  0.6168,  0.6169],\n",
      "          ...,\n",
      "          [ 0.6152,  0.6155,  0.6158,  ...,  0.6173,  0.6172,  0.6171],\n",
      "          [ 0.6156,  0.6158,  0.6160,  ...,  0.6170,  0.6170,  0.6170],\n",
      "          [ 0.6160,  0.6161,  0.6162,  ...,  0.6168,  0.6169,  0.6170]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437],\n",
      "          [ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437],\n",
      "          [ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437],\n",
      "          ...,\n",
      "          [ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437],\n",
      "          [ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437],\n",
      "          [ 0.9436,  0.9436,  0.9436,  ...,  0.9437,  0.9437,  0.9437]],\n",
      "\n",
      "         [[ 0.5319,  0.5323,  0.5328,  ...,  0.5355,  0.5356,  0.5357],\n",
      "          [ 0.5317,  0.5321,  0.5325,  ...,  0.5356,  0.5357,  0.5359],\n",
      "          [ 0.5314,  0.5318,  0.5323,  ...,  0.5358,  0.5359,  0.5360],\n",
      "          ...,\n",
      "          [ 0.5335,  0.5340,  0.5345,  ...,  0.5367,  0.5365,  0.5363],\n",
      "          [ 0.5341,  0.5344,  0.5348,  ...,  0.5363,  0.5363,  0.5363],\n",
      "          [ 0.5347,  0.5349,  0.5350,  ...,  0.5359,  0.5360,  0.5362]],\n",
      "\n",
      "         [[-0.4529, -0.4529, -0.4529,  ..., -0.4528, -0.4528, -0.4528],\n",
      "          [-0.4529, -0.4529, -0.4529,  ..., -0.4528, -0.4528, -0.4528],\n",
      "          [-0.4529, -0.4529, -0.4529,  ..., -0.4528, -0.4528, -0.4528],\n",
      "          ...,\n",
      "          [-0.4529, -0.4529, -0.4528,  ..., -0.4528, -0.4528, -0.4528],\n",
      "          [-0.4529, -0.4528, -0.4528,  ..., -0.4528, -0.4528, -0.4528],\n",
      "          [-0.4528, -0.4528, -0.4528,  ..., -0.4528, -0.4528, -0.4528]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset , DataLoader, random_split\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from imgDataset import imgDataset , custom_collate\n",
    "from EAST import EAST\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0a830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "directory_train = os.getenv('Directory_train')\n",
    "directory_train_textAndCoords = os.getenv('directory_train_textAndCoords')\n",
    "directory_test = os.getenv('Directory_test')\n",
    "directory_test_textAndCoords = os.getenv('directory_test_textAndCoords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c18ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path_imgs and path_labels\n",
    "path_imgs = os.listdir(directory_train)\n",
    "path_labels = os.listdir(directory_train_textAndCoords)\n",
    "\n",
    "# Generate paths for training images and labels\n",
    "train_img_paths = [os.path.join(directory_train, f) for f in path_imgs]\n",
    "train_label_paths = [os.path.join(directory_train_textAndCoords, f) for f in path_labels]\n",
    "\n",
    "#print(train_img_paths)\n",
    "#print(train_label_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9be443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 360, 640])\n",
      "First Coords: [[243, 108, 277, 105, 279, 121, 244, 124], [0, 180, 43, 177, 45, 192, 0, 200], [24, 197, 31, 196, 32, 203, 25, 205], [132, 117, 143, 113, 147, 121, 133, 127]]\n",
      "First Coords:4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFirst Coords:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(coords)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[33;03m'''max_len = max(len(train_dataset[j][2]) for j in range(len(train_dataset)))\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03mpad_len = max_len - len(train_dataset[3][2])\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[33;03mprint(pad_len)'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m batch = \u001b[43mcustom_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Balan\\OneDrive\\Documents\\projects\\EAST_model_Pytorch\\model\\imgDataset.py:86\u001b[39m, in \u001b[36mcustom_collate\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pad_len):\n\u001b[32m     85\u001b[39m     padded_coords.append(torch.tensor([\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m]))\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_coords\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[32m     87\u001b[39m imgs_alt.append(imgs)\n\u001b[32m     88\u001b[39m labels_alt.append(labels)\n",
      "\u001b[31mTypeError\u001b[39m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "train_dataset = [train_img_paths, train_label_paths]\n",
    "train_dataset = imgDataset(train_img_paths, train_label_paths)\n",
    "img, labels, coords = train_dataset[3]\n",
    "\n",
    "print(f\"Image shape: {img.shape}\") # Should be [1, 360, 360] since it's grayscale\n",
    "print(f\"First Coords: {coords}\")\n",
    "print(f\"First Coords:{len(coords)}\")\n",
    "\n",
    "'''max_len = max(len(train_dataset[j][2]) for j in range(len(train_dataset)))\n",
    "pad_len = max_len - len(train_dataset[3][2])\n",
    "print(pad_len)'''\n",
    "\n",
    "batch = custom_collate(train_dataset)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effd0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bddb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spltining the dataset into training and validation sets\n",
    "val_split = 0.2\n",
    "training_size = int((1 - val_split) * len(train_dataset))\n",
    "val_size = len(train_dataset) - training_size\n",
    "training_dataset, val_dataset = random_split(train_dataset, [training_size, val_size])\n",
    "loader_train = DataLoader(training_dataset, batch_size=32, shuffle=True, collate_fn = custom_collate)\n",
    "loader_val = DataLoader(val_dataset, batch_size=32, shuffle=True, collate_fn = custom_collate)\n",
    "\n",
    "#print(f\"loader_train: {loader_train}\")\n",
    "#print(f\"loader_val: {loader_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EAST(color_channel=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loasding model if it exists\n",
    "if os.getenv('Load_model') == 'True': \n",
    "    model.load_state_dict(torch.load(os.getenv('model_path')))\n",
    "    print(\"Model loaded successfully\")\n",
    "else:\n",
    "    print(\"Model not load, starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defualt model otipions\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "cycles = 12\n",
    "train_model(model = model, loader_train = loader_train, loader_val = loader_val, criterion = criterion, optimizer = optimizer, cycles = cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bc0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = os.getenv('Model_save_path', 'east_model.pth')\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-east",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
